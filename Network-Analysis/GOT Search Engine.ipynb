{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7147881a",
   "metadata": {},
   "source": [
    "# Search Engine des alias d'un personnage de Game of Thrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(lab=False)\n",
    "sns.set()\n",
    "\n",
    "SAVE_PATH = (\n",
    "    \"/home/samy/csv_pickle_parquet/\"  # Le directory ou se trouve les documents d'études\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWOIAF_LIST_URL = \"https://awoiaf.westeros.org/index.php/List_of_characters\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.118 Safari/537.36\"\n",
    "}\n",
    "\n",
    "r = requests.get(AWOIAF_LIST_URL, headers=HEADERS)\n",
    "\n",
    "soup = BeautifulSoup(r.text)\n",
    "items = soup.find_all(\"ul\")[9:35]\n",
    "li_list = []\n",
    "for ul in items:\n",
    "    temp = ul.find_all(\"li\")\n",
    "    for elem in temp:\n",
    "        li_list.append(elem.find(\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f765f06",
   "metadata": {},
   "source": [
    "### Création d'un dictionnaire avec tout les liens de téléchargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79093600",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_url_dict = {}\n",
    "for item in li_list:\n",
    "    title = item.get(\"title\")\n",
    "    if title:\n",
    "        href = item.get(\"href\")\n",
    "        characters_url_dict[title] = \"https://awoiaf.westeros.org\" + href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b11dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_url_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ba6a0",
   "metadata": {},
   "source": [
    "### Téléchargement des données et transformation en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_wiki = pd.DataFrame(columns=[\"character\", \"raw_data\"])\n",
    "\n",
    "\n",
    "for chara in tqdm(characters_url_dict.keys()):\n",
    "    fetched_html = requests.get(characters_url_dict[chara], headers=HEADERS).text\n",
    "    raw_data_wiki.loc[len(raw_data_wiki), :] = [chara, fetched_html]\n",
    "\n",
    "\n",
    "raw_data_wiki.to_csv(SAVE_PATH + \"awoiaf_raw_html_v2.csv\", sep=\",\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2e7b0",
   "metadata": {},
   "source": [
    "### Obtention de la page html pour un personnage en particulier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "\n",
    "FILENAME = SAVE_PATH + \"awoiaf_raw_html.csv\"\n",
    "ENCODING = \"utf-8\"\n",
    "\n",
    "# Deux solutions pour lire des données : import via pandas ou streaming\n",
    "\n",
    "\n",
    "def get_html_streaming(\n",
    "    character,\n",
    "):  # Cette solution est intéressante si la volumétrie de données est très importante (temps d'exec au pire des cas : 3.76s)\n",
    "    with codecs.open(FILENAME, \"r\", ENCODING) as fp:\n",
    "        reader = csv.reader(fp)\n",
    "        i = 0\n",
    "        for row in tqdm(reader):\n",
    "            if row[0] == character:\n",
    "                return row[1]\n",
    "        raise Exception(\"Character not found\")\n",
    "\n",
    "\n",
    "def get_html_pandas(\n",
    "    character,\n",
    "):  # Solution naive mais la plus efficace dans le cas présent (temps d'exec moyen : 1.72s)\n",
    "    data = pd.read_csv(FILENAME)\n",
    "    liste = data[data[\"character\"] == character].raw_data.tolist()\n",
    "    if liste:\n",
    "        return liste[0]\n",
    "    else:\n",
    "        raise Exception(\"Character not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f4a06",
   "metadata": {},
   "source": [
    "### Obtention des alias d'un personnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5f91f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "BOOKS_TITLE = {\n",
    "    \"A Game of Thrones\": \"GOT1.txt\",\n",
    "    \"A Clash of Kings\": \"GOT2.txt\",\n",
    "    \"A Storm of Swords\": \"GOT3.txt\",\n",
    "    \"A Feast for Crows\": \"GOT4.txt\",\n",
    "    \"A Dance with Dragons\": \"GOT5.txt\",\n",
    "}\n",
    "\n",
    "CHAR_URLS = []\n",
    "for item in li_list:\n",
    "    title = item.get(\"title\")\n",
    "    if title:\n",
    "        href = item.get(\"href\")\n",
    "        CHAR_URLS.append(href)\n",
    "\n",
    "\n",
    "def get_aliases(soup):\n",
    "    aliases_list = []\n",
    "    aliases_html_th = soup.find(\"table\", class_=\"infobox\").find(\"th\", text=\"Aliases\")\n",
    "    if aliases_html_th:\n",
    "        aliases_html_td = aliases_html_th.find_next(\"td\").find_all(\"li\")\n",
    "        for elmt in aliases_html_td:\n",
    "            name = elmt.text\n",
    "            name = (\n",
    "                \"\".join([i for i in name if not i.isdigit()])\n",
    "                .replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "            )\n",
    "            aliases_list.append(name)\n",
    "    return aliases_list\n",
    "\n",
    "\n",
    "def get_alias(soup):\n",
    "    name = []\n",
    "    alias_html_th = soup.find(\"table\", class_=\"infobox\").find(\"th\", text=\"Alias\")\n",
    "    if alias_html_th:\n",
    "        alias = alias_html_th.find_next(\"td\").text\n",
    "        alias = (\n",
    "            \"\".join([i for i in alias if not i.isdigit()])\n",
    "            .replace(\"[\", \"\")\n",
    "            .replace(\"]\", \"\")\n",
    "            .strip()\n",
    "        )\n",
    "        name.append(alias)\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_title_name(soup):\n",
    "    title_html_h1 = soup.find(\"h1\").text\n",
    "    return title_html_h1\n",
    "\n",
    "\n",
    "def get_infobox_name(soup):\n",
    "    infobox = soup.find(\"table\", class_=\"infobox\")\n",
    "    sub_table = infobox.find(\"table\")\n",
    "    if sub_table:\n",
    "        infobox_name = sub_table.find_all(\"td\")[1]\n",
    "        span = infobox_name.find(\"span\")\n",
    "        if span:\n",
    "            span.decompose()\n",
    "        return infobox_name.text\n",
    "    else:\n",
    "        return infobox.find_next(\"th\").text\n",
    "\n",
    "\n",
    "def get_text_length(soup):\n",
    "    text_list = soup.find_all(\"p\")\n",
    "    text = \"\".join(i.text for i in text_list)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = re.sub(r\"\\[\\d+\\]\", \"\", text)\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def get_books(soup):\n",
    "    book_list = []\n",
    "    books_html_th = soup.find(\"table\", class_=\"infobox\").find(\"th\", text=\"Books\")\n",
    "    if books_html_th:\n",
    "        books_html_td = books_html_th.find_next(\"td\").find_all(\"li\")\n",
    "        for elmt in books_html_td:\n",
    "            name = elmt.text\n",
    "            book_list.append(name)\n",
    "    return book_list\n",
    "\n",
    "\n",
    "def get_book(soup):\n",
    "    name = []\n",
    "    book_html_th = soup.find(\"table\", class_=\"infobox\").find(\"th\", text=\"Book\")\n",
    "    if book_html_th:\n",
    "        book = book_html_th.find_next(\"td\").text\n",
    "        book = (\n",
    "            \"\".join([i for i in book if not i.isdigit()])\n",
    "            .replace(\"[\", \"\")\n",
    "            .replace(\"]\", \"\")\n",
    "            .strip()\n",
    "        )\n",
    "        name.append(book)\n",
    "    return name\n",
    "\n",
    "\n",
    "def association_name_number(book_list, app_list):\n",
    "    new_book_list = list()\n",
    "    for i in range(len(book_list)):\n",
    "        book_clean = book_list[i].strip()\n",
    "        if book_clean in BOOKS_TITLE:\n",
    "            new_book_list.append(BOOKS_TITLE[book_clean])\n",
    "        else:\n",
    "            app_list[i] = \"\"\n",
    "    return new_book_list\n",
    "\n",
    "\n",
    "def split_name_appearance(book_app_list):\n",
    "    book_name_list = [element.split(\"(\")[0] for element in book_app_list]\n",
    "    app_list = [element.split(\"(\")[1].replace(\")\", \"\") for element in book_app_list]\n",
    "    book_list = association_name_number(book_name_list, app_list)\n",
    "    new_app_list = []\n",
    "    for elmt in app_list:\n",
    "        if elmt:\n",
    "            new_app_list.append(elmt)\n",
    "    return book_list, new_app_list\n",
    "\n",
    "\n",
    "def get_page_rank(soup):\n",
    "    rank = 0\n",
    "    link_list = soup.find_all(\"a\")\n",
    "    for link in link_list:\n",
    "        href = link.get(\"href\")\n",
    "        if href in CHAR_URLS:\n",
    "            rank += 1\n",
    "    return rank\n",
    "\n",
    "\n",
    "def get_total_information(character):\n",
    "    html = get_html_streaming(character)\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    book_list = get_books(soup) + get_book(soup)\n",
    "    books, appearances = split_name_appearance(book_list)\n",
    "\n",
    "    return {\n",
    "        \"name_title\": get_title_name(soup),\n",
    "        \"name_infobox\": get_infobox_name(soup),\n",
    "        \"aliases\": get_aliases(soup) + get_alias(soup),\n",
    "        \"page_rank\": get_page_rank(soup),\n",
    "        \"text_length\": get_text_length(soup),\n",
    "        \"books\": books,\n",
    "        \"nature_of_appearance\": appearances,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbd1b9",
   "metadata": {},
   "source": [
    "###### Cas possibles en résultat du search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2595478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1007it [00:01, 811.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 s, sys: 80.1 ms, total: 1.39 s\n",
      "Wall time: 1.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name_title': 'Eddard Stark',\n",
       " 'name_infobox': 'Eddard Stark',\n",
       " 'aliases': ['Ned', 'The quiet wolf', 'The Ned'],\n",
       " 'page_rank': 410,\n",
       " 'text_length': 24278,\n",
       " 'books': ['GOT1.txt', 'GOT2.txt', 'GOT3.txt', 'GOT4.txt', 'GOT5.txt'],\n",
       " 'nature_of_appearance': ['POV',\n",
       "  'mentioned',\n",
       "  'mentioned',\n",
       "  'mentioned',\n",
       "  'mentioned']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Exemple : Eddard Stark\n",
    "get_total_information(\"Eddard Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b6bc24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1616it [00:01, 885.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 s, sys: 90.5 ms, total: 1.91 s\n",
      "Wall time: 1.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name_title': 'Hodor',\n",
       " 'name_infobox': 'Walder',\n",
       " 'aliases': ['Hodor'],\n",
       " 'page_rank': 75,\n",
       " 'text_length': 12982,\n",
       " 'books': ['GOT1.txt', 'GOT2.txt', 'GOT3.txt', 'GOT4.txt', 'GOT5.txt'],\n",
       " 'nature_of_appearance': ['appears',\n",
       "  'appears',\n",
       "  'appears',\n",
       "  'mentioned',\n",
       "  'appears']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Exemple : Hodor\n",
    "get_total_information(\"Hodor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
